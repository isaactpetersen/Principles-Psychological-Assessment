# Objective Personality Testing {#objective-personality}

## Overview of Personality Tests {#overview-objective-personality}

There are two main types of personality tests: objective personality tests and [projective personality tests](#projective-personality).\index{personality assessment!objective}\index{personality assessment!projective}
Of course, no measure is truly "objective" but some measures are more or less so.\index{personality assessment!objective}
In a so-called *objective personality test* (or structured personality test), a stimulus is presented to a respondent, who makes a closed-ended (constrained) response, such as True/False or Likert ratings.\index{personality assessment!objective}\index{Likert scale}
Examples of objective personality or symptomatology tests include the [Minnesota Multiphasic Personality Inventory](#mmpi) (MMPI) and the Beck Depression Inventory (BDI).\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
In a [*projective personality test*](#projective-personality), an ambiguous stimulus is presented to a respondent, who is asked to make an open-ended response.\index{personality assessment!projective}
Examples of [projective personality tests](#projective-personality) include the [Rorschach Inkblot Test](#rorschach) and the [Thematic Apperception Test](#tat) (TAT).\index{personality assessment!projective}\index{Rorschach Inkblot Test}\index{Thematic Apperception Test}
[Projective tests](#projective-personality) have largely fallen by the wayside now, but it is still helpful to think about their potential advantages.\index{personality assessment!projective}
[Projective tests](#projective-personality) are described in further detail in Chapter \@ref(projective).\index{personality assessment!projective}

### Projective Personality Tests {#projectivePersonalityTests}

In a [projective personality test](#projective-personality), the client's response is not limited.\index{personality assessment!projective}
[Projective personality tests](#projective-personality) were designed from a psychodynamic perspective, and they are supposed to have limitless variability and therefore a freer access to the client's internal world.\index{personality assessment!projective}\index{psychoanalysis}
However, Card V of the [Rorschach Inkblot Test](#rorschach) looks like a moth or a bat, and around 90% of respondents likely give that response [@Wiggins1973], so [projective tests](#projective-personality) are not completely limitless.\index{personality assessment!projective}\index{Rorschach Inkblot Test}
[Projective personality tests](#projective-personality) are designed to have ambiguous content.\index{personality assessment!projective}
This is, in part, to make them hard to figure out what is being assessed.\index{personality assessment!projective}
That is, they tend to have low [face validity](#faceValidity).\index{personality assessment!projective}\index{validity!face}
However, even so-called objective personality tests can have items that are ambiguous and that function similarly to a [projective test](#projective-personality).\index{personality assessment!objective}\index{personality assessment!projective}
For instance, one of the items on the original [MMPI](#mmpi) asks respondents whether they like mechanics magazines.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
But in modern times, many people have never looked at a mechanics magazine.\index{personality assessment!objective}
So, it becomes like a [Rorschach](#rorschach) question because the client starts to think about other factors.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{personality assessment!projective}\index{Rorschach Inkblot Test}

Scoring of [projective tests](#projective-personality) does not rely on the client's insight, so [projective tests](#projective-personality) might get past [social desirability](#methodBias) of clients' responses and potential defensiveness.\index{personality assessment!projective}\index{response style!social desirability}
Therefore, [projective tests](#projective-personality) are potentially difficult to fake.\index{personality assessment!projective}
*Faking good* means to present oneself as better (or in a more positive light) than one actually is, whereas *faking bad* means to present oneself as worse (or in a more negative light) than one actually is.\index{personality assessment!projective}\index{faking!good}\index{faking!bad}
Faking or feigning responses often happens for incentives due to external reasons.\index{faking!good}\index{faking!bad}
For instance, a client may want to fake good on a test if it allows them to get a job or to win custody of a child.\index{personality assessment!projective}\index{faking!good}
By contrast, a client may want to fake bad to receive disability insurance or to be pronounced not guilty by reason of insanity.\index{personality assessment!projective}\index{faking!bad}

As of 1995, the [TAT](#tat) and [Rorschach](#rorschach) were the #5 and #6 most widely used assessments, respectively, by clinical psychologists [@Watkins1995].\index{personality assessment!projective}\index{Rorschach Inkblot Test}\index{Thematic Apperception Test}
However, they and other [projective techniques](#projective-personality) have lost considerable ground since then.\index{personality assessment!projective}

### Objective Personality Tests {#objectivePersonalityTests}

In contrast to [projective personality tests](#projective-personality), objective personality tests, the client's responses are substantially constrained to the possible answers.\index{personality assessment!projective}\index{personality assessment!objective}
Moreover, objective personality tests tend to be cheap and fast to administer, and can be scored by computers now.\index{personality assessment!objective}
In addition, objective tests have more [reliable](#reliability) scoring than [projective tests](#projective-personality).\index{personality assessment!objective}\index{personality assessment!projective}\index{personality assessment!objective!reliability of}
It takes a very long time to score the [Rorschach Inkblot Test](#rorschach) and it it still has very low [reliability](#reliability).\index{personality assessment!projective}\index{Rorschach Inkblot Test}\index{personality assessment!projective!reliability of}
With an objective test, by contrast, scoring [reliability](#reliability) approaches perfection.\index{personality assessment!objective}\index{personality assessment!objective!reliability of}
The earliest examples of objective personality tests were the [MMPI](#mmpi) and the Strong Vocational Interest Blank.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
The [MMPI](#mmpi) assesses personality, whereas the Strong Vocational Interest Blank assessed preferences for different jobs or professions.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
An overview of objective personality tests is provided by @Wiggins1973.\index{personality assessment!objective}

## Example of an Objective Personality Test: MMPI {#mmpi}

The MMPI is an example of a so-called "objective" personality test.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
But the MMPI and other objective personality tests are not truly objective.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
Consider an example of a True/False item from the MMPI: "I hardly ever notice my heart pounding and I am seldom short of breath."\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
The item is intended to assess somatic symptom disorder, with a response of "false" being more indicative of disorder.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
But there are other factors that could influence a person's response to the question besides whether the person has somatic symptom disorder.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
Figure \@ref(fig:somaticSymptom) depicts how a person's response to the question could be influenced by several factors.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
A comorbidity of somatic symptom disorder could make it more likely that a person answers with a response of "false", in line with somatic symptom disorder.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
In addition, a person's insight ability may influence whether they answer with a response of "false."\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
Also, people who exercise more may experience a pounding heart and shortness of breath more frequently (i.e., while exercising), and therefore answer with a response of "false."\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
In sum, the item and the test as a whole is clearly not "objective" because constructs in the questions are not clearly defined.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
What does a "pounding heart" mean?\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
How much is "hardly ever"?\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
People may define "seldom" differently.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}

```{r somaticSymptom, out.width = "100%", fig.align = "center", fig.cap = "Depiction of Some of the Factors That Could Influence a Respondent's Answer to the True/False Question: 'I hardly ever notice my heart pounding, and I am seldom short of breath.'.", echo = FALSE}
knitr::include_graphics("./Images/somaticSymptom.png")
```

There are multiple forms of [measurement error](#measurementError) for a given item.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}
For instance, there are situational sources of [measurement error](#measurementError).\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}
Consider the item "I hardly ever notice my heart pounding, and I am seldom short of breath."\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}
For example, how many stairs the participant climbed to get to the lab could influence their response to the question.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}
Other situational factors could include whether they are dehydrated, whether they have a cold or are sick, and what they did over the past week.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}
Another form of [measurement error](#measurementError) could result from the purpose of test taking.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}
It is important to consider the purpose of the assessment.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}
For example, if the assessment is for disability payments or to get a physical job, such as a firefighter, it may change a person's answers.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}
[Response biases](#methodBias), such as social desirability, could also influence a person's answers.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}\index{response style}\index{response style!social desirability}
In addition, memory limitations of the person could influence their responses.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{measurement error}

There have been multiple versions of the MMPI.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
@Graham2022 provide an overview of how the MMPI was developed.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
The original MMPI was developed using the [external approach](#externalApproach) to scale construction.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{assessment development!external approach}
The second version of the MMPI (MMPI-2) placed greater emphasis on [content validity](#contentValidity) of the items, on removing items with outdated or offensive language, and on updating the [norms](#norm) to be more representative.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}\index{validity!content}\index{norm}
Later, restructured versions of the MMPI-2 were created, which became known as the MMPI-2-Restructured Forms (MMPI-2-RF).\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
Evidence on the MMPI-2-RF is reviewed by @Sellbom2019.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
The latest version of the MMPI is the MMPI-3.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}

## Problems with Objective True/False Measures {#problemsTrueFalseMeasures}

There are a number of problems with objective True/False measures.\index{personality assessment!objective}
However, the problems are not necessarily unique to objective personality measures or to True/False measures.\index{personality assessment!objective}

One problem is related to the [response biases](#methodBias) of acquiescence and disacquiescence.\index{personality assessment!objective}\index{response style}\index{method bias}
*Acquiescence* occurs when the person agrees in response to items regardless of item content.\index{personality assessment!objective}\index{response style!acquiescence}
Acquiescence occurs oftentimes when the participant is just going along because they think the experimenter may want them to have certain characteristics, therefore they often just say "TRUE" a lot.\index{personality assessment!objective}\index{response style!acquiescence}
That is, they may want to please the investigators.\index{personality assessment!objective}\index{response style!acquiescence}
*Disacquiescence*, by contrast, is when the person disagrees in response to the items regardless of item content.\index{personality assessment!objective}\index{response style!disacquiescence}
Disacquiescence is also called opposition bias.\index{personality assessment!objective}\index{response style!disacquiescence}
Disacquiescence may occur if the person does not think they have the disorder or problem of the characteristics being explored.\index{personality assessment!objective}\index{response style!disacquiescence}

True/False measures, just like other questionnaire formats, are influenced by multiple sources of variation.\index{personality assessment!objective}
In an objective personality test, there is a high demand on respondents.\index{personality assessment!objective}
For instance, on the [MMPI](#mmpi), respondents must be aware of recall over an unspecified period of time, which can cause confusion.\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
The high demand on respondents can lead to inaccuracy of individuals' reading of the items.\index{personality assessment!objective}
Additional sources of information could influence the respondents' answers to the item "I hardly ever notice my heart pounding, and I am seldom short of breath."\index{personality assessment!objective}
Some respondents may be intoxicated while answering questions, which could influence physiological experiences.\index{personality assessment!objective}
Some respondents may have comorbordities that influence their responses.\index{personality assessment!objective}
Psychological and medical comorbidities could cause difficulty in interpreting the questions.\index{personality assessment!objective}
For example, the respondent may wonder whether the investigator is inquiring about heart beating that reflects anxiety versus heart beating that reflects high blood pressure.\index{personality assessment!objective}

In addition, there are effort differences that influence people's responding.\index{personality assessment!objective}
There has been a recent resurgence in how to assess respondents' effort.\index{personality assessment!objective}
There are often limits to predicting phenomena due to individuals not putting effort into answering questions.\index{personality assessment!objective}
Other potential sources of variation in an item could include psychopathology, stress, physical fitness, age, and gender.\index{personality assessment!objective}
For instance, older people are more likely to notice shortness of breath because their lung capacity is less than what it used to be.\index{personality assessment!objective}
Moreover, women more likely to say "FALSE" to this item than men, but the item has less social desirability bias than some other items, so women could be putting in more effort and giving different responses than men.\index{personality assessment!objective}\index{bias!social desirability}

In sum, lots of factors beyond the construct of interest can influence a response on an item.\index{personality assessment!objective}
It is valuable to scan through your measures and consider what goes into a person's answers.\index{personality assessment!objective}
It is important to keep the content in mind of all things contributing to scores, and you should consider these potential factors when interpreting results!\index{personality assessment!objective}

Another problem with some questions are compound questions, also called double-barreled questions.\index{personality assessment!objective}
Double-barreled questions following the structure: $\text{T/F: X} + \text{Y}$.\index{personality assessment!objective}
An example of a compound question is, "True or False: Cars should be faster and safer."\index{personality assessment!objective}
It is unclear which components of a compound question people are responding to.
In conclusion, every objective test is partly [projective](#projective-personality)—that is, the stimuli are interpreted in different ways by different people.\index{personality assessment!objective}\index{personality assessment!projective}

## Approaches to Developing Personality Measures {#developingPersonalityMeasures}

There are three primary approaches to developing personality measures and other scales:\index{assessment development!approaches to}

1. An [external approach](#externalApproach) to scale construction, also called an empirical approach or criterion-keyed approach\index{assessment development!approaches to}\index{assessment development!external approach}
1. A [deductive approach](#deductiveApproach) to scale construction, also called a rational, theoretical, or intuitive approach\index{assessment development!approaches to}\index{assessment development!deductive approach}
1. An [inductive approach](#inductiveApproach) to scale construction, also called an internal or item-metric approach\index{assessment development!approaches to}\index{assessment development!inductive approach}

However, these approaches are not mutually exclusive and can be combined.\index{assessment development!approaches to}

### External Approach to Scale Contruction {#externalApproach}

The external approach to developing a personality measure is also called the empirical approach or the criterion-keyed approach.\index{assessment development!approaches to}\index{assessment development!external approach}
The external approach relies on an external [criterion](#criterionValidity).\index{assessment development!approaches to}\index{assessment development!external approach}\index{criterion}
In general, a criterion-keyed approach examines scores on items in relation to the [criterion](#criterionValidity), and selects items that are associated with the [criterion](#criterionValidity), regardless of the item content.\index{assessment development!approaches to}\index{assessment development!external approach}\index{criterion}\index{validity!criterion}
The [MMPI](#mmpi) is an example of a scale that was developed using the external approach.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}
For the [MMPI](#mmpi), the [criterion](#criterionValidity) was a group (i.e., a [criterion](#criterionValidity) group approach), or more accurately, multiple groups: patients with different disorders and controls.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}
The original [MMPI](#mmpi) was not developed based on theory (e.g., theoretical understanding of the construct of depression); instead, it was developed based on items' empirical associations with a [criterion](#criterionValidity) group.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}\index{theory}\index{empiricism}
Because an external approach relies on an external [criterion](#criterionValidity), if people lose interest in the scale [criterion](#criterionValidity), the scale loses interest.\index{assessment development!approaches to}\index{assessment development!external approach}\index{criterion}

Consider the development of the [MMPI](#mmpi) as an example of a measure that was developed using the external approach to scale construction.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}
The developers grouped people together based on their [criterion](#criterionValidity) status, for example one group of people with schizophrenia and a control group that does not have mental disorders.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}
How did they develop the test?\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}
The idea of the external approach is to let nature decide what goes into the test.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{empiricism}
So, the [MMPI](#mmpi) developers sampled thousands of questions very broadly from pre-existing questionnaires of personality, symptoms, etc.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}
Then, they had the [criterion](#criterionValidity) groups (e.g., schizophrenia) and control groups answer the questions.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}
They examined the item responses to determine which items discriminate between groups (i.e., which items are associated with [criterion](#criterionValidity) group status).\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}\index{validity!criterion}
And if an item(s) is good at discriminating between the [criterion](#criterionValidity) and control groups, the items are selected for the measure.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}\index{validity!criterion}\index{empiricism}
It was purely empirical business—i.e., [dustbowl empiricism](#theoryEmpiricism).\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}\index{validity!criterion}\index{empiricism}
In sum, using an external approach, item selection depends on the discriminatory power of each item to inform about an external [criterion](#criterionValidity) of interest.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}\index{validity!criterion}\index{empiricism}\index{discrimination}
Such an approach does not require having any theoretical assumptions about item functioning.\index{assessment development!approaches to}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{criterion}\index{validity!criterion}\index{empiricism}\index{theory}

#### Pros {#externalApproachPros}

There are several pros of using the external approach to develop measures:\index{assessment development!approaches to}\index{assessment development!external approach}

- You do not need to know anything—it requires no theory or theoretical knowledge about disorders and their etiology\index{assessment development!approaches to}\index{assessment development!external approach}
- There is likely to be some generalizability of the utility of the measure in the future because there is some carryover of [criterion-related validity](#criterionValidity)\index{assessment development!approaches to}\index{assessment development!external approach}\index{validity!criterion}\index{validity!utility}
- The measure has some practical utility given its relation to [criteria](#criterionValidity) of interest\index{assessment development!approaches to}\index{assessment development!external approach}\index{validity!utility}
- "Subtle items" with poor [face validity](#faceValidity) can be selected solely based on their discriminatory power.\index{assessment development!approaches to}\index{assessment development!external approach}\index{discrimination}\index{validity!face}\index{subtle item}
Subtle items are items that neither you nor the respondent predicted would show differences between groups.\index{assessment development!approaches to}\index{assessment development!external approach}\index{subtle item}
Subtle items provide an advantage that the data are moving beyond our ignorance.\index{assessment development!approaches to}\index{assessment development!external approach}\index{subtle item}
It is also an advantage that clients cannot fake subtle items as well as they can more obvious items.\index{assessment development!approaches to}\index{assessment development!external approach}\index{subtle item}

#### Cons {#externalApproachCons}

There are also cons of using the external approach to develop measures:\index{assessment development!approaches to}\index{assessment development!external approach}

- Measures developed using the external approach have lower [content validity](#contentValidity) and/or [face validity](#faceValidity) because they include subtle items.\index{assessment development!external approach}\index{validity!content}\index{validity!face}
For example, the original version of the [MMPI](#mmpi) had low [content validity](#contentValidity) and [face validity](#faceValidity).\index{assessment development!external approach}\index{validity!content}\index{validity!face}\index{Minnesota Multiphasic Personality Inventory}
Using the external approach, it is possible to construct a scale that makes no sense due to lack of consideration of [face validity](#faceValidity).\index{assessment development!external approach}\index{validity!face}
- The success of the external approach depends highly on the quality of the [criterion](#criterionValidity) and control groups—if a [criterion](#criterionValidity) falls out of favor as an indicator of the construct (or interest fades) then the [utility](#validity) of the test decreases because it is no longer applicable.\index{assessment development!external approach}\index{validity!utility}\index{criterion}
- Items will not always generalize because the generalizability depends on the representativeness of the sample and the quality of the groups—if you select poor groups, it is not a representative sample, which results in a biased measure.\index{assessment development!external approach}\index{validity!external}
The [validity](#validity) of the scale depends on the representativeness of your groups in regard to the [criterion](#criterionValidity) of interest.\index{assessment development!external approach}\index{validity!external}\index{criterion}
It is possible that your findings might not be generalizable if your sample is not—this is especially problematic when you rely only on data and not on theory.\index{assessment development!external approach}\index{validity!external}\index{criterion}\index{empiricism}\index{theory}
    - An example of the importance of the representativeness of the sample comes from the original [MMPI](#mmpi).\index{assessment development!external approach}\index{validity!external}\index{Minnesota Multiphasic Personality Inventory}
The [norms](#norm) of the original [MMPI](#mmpi) were based on largely White participants from Scandinavian, German, and Irish Descent in the Midwestern U.S., with an average of an 8th grade education.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{norm}
The [norms](#norm) became known as "Minnesota farmers."\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{norm}
Therefore, "Minnesota normals" (i.e., the control group) were pretty "dull" normals.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{norm}
In addition, to be included in the [norms](#norm), the respondents for the [MMPI](#mmpi) had to be waiting in the hospital (not everyone does that for family in the hospital) and had to be kind enough to take a 4–5 hour measure for psychologists (not all would do this).\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{norm}
For all of these reasons, there were issues with poor generalizability of the original [MMPI](#mmpi) [norms](#norm) in the broader population.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{norm}\index{validity!external}
A scale is most likely to be valid when it is used with similar populations and in similar conditions.\index{assessment development!external approach}\index{validity!external}
- Shrinkage often occurs when using a measure developed using an external approach.\index{assessment development!external approach}\index{shrinkage}
As described in Section \@ref(modelAccuracy-actuarial), *shrinkage* is when variables with stronger predictive power in the original data set tend to show somewhat smaller predictive power (smaller [validity](#validity) coefficients) when applied to new groups.\index{assessment development!external approach}\index{shrinkage}\index{validity!coefficient of}
When variables are selected empirically, they tend to show less predictive power (smaller [validity](#validity) coefficients) when applied to new groups during cross-validation.\index{assessment development!external approach}\index{shrinkage}\index{validity!coefficient of}\index{cross-validation}\index{empiricism}
Shrinkage reflects a model [over-fitting](#overfitting), because it is somewhat capitalizing on chance in selecting items.\index{shrinkage}\index{over-fitting}\index{assessment development!external approach}
Many subtle items may be instances of Type I error (false positives).\index{assessment development!external approach}\index{subtle item}\index{false positive}
Shrinkage is especially likely when the original sample is small and/or unrepresentative and the number of variables considered for inclusion is large.\index{assessment development!external approach}\index{shrinkage}\index{validity!external}
- Externally developed measures also have a problem of communicability [@Burisch1984].\index{assessment development!external approach}
For something to have meaning to others, it should have connection to constructs, which may not be true for many measures developed using the external approach.\index{assessment development!external approach}\index{construct}
- It can take a long time to develop measures using the external approach, and they tend to be longer to administer because of having more items.\index{assessment development!external approach}
For instance, there are 567 items in the [MMPI-2](#mmpi).\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}

#### MMPI Examples {#mmpiExamples}

Paul Meehl wrote his dissertation to develop the K scale of the [MMPI](#mmpi) to attempt to detect faking good.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!good}
In the context of the [MMPI](#mmpi), faking good would involve under-reporting of symptoms.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!good}
He developed the K scale based on all positive qualities that around half of people typically endorse.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!good}
So, it is not obvious that the items reflect faking good, and if someone is trying to respond in a socially desirable way, they endorse more of these positive qualities.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!good}
There is also a "faking bad" version of the scale, too.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!bad}
The "faking bad" (F) scale was developed as an attempt to detect malingering (over-reporting of symptoms).\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!bad}

However, the [MMPI](#mmpi) could pathologize normality in some cases.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!bad}
Some psychotic patients may have been identified as "faking bad" because they actually have had a lot of odd experiences.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!bad}
And very healthy people may have gotten higher score on "faking good," but they just may be very positive and well-adjusted.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{faking!good}
As examples from the original [MMPI](#mmpi) from 1940, male teenagers tended to have elevated scores on the psychopathy and mania scales.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}
Graduate students, including female graduate students, tended to have higher "masculine" scores on the Masculinity/Femininity (Mf) scale.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}
This shows that non-clinical samples can still have "clinical" scores.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}
In the 1930s–1940s, there was an emphasis on developing empirically based measures, where the researchers rely on data, not theory as had previously been emphasized.\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}\index{empiricism}\index{theory}

### Deductive Approach to Scale Construction {#deductiveApproach}

The deductive approach to developing a personality measure is also called a rational, theoretical, or intuitive approach.\index{assessment development!deductive approach}
Using a *deductive approach*, the choice and definition of constructs precede and govern the formulation of items.\index{assessment development!deductive approach}
Item pools are generated using theoretical considerations, and item selection depends on possessing a rich theoretical knowledge about the construct and selecting which items assess the construct the best.\index{assessment development!deductive approach}
In a deductive approach, the measure developer deduces the content; they do not rely on [criterion](#criterionValidity) data to select the content.\index{assessment development!deductive approach}\index{criterion}
Deducing the content involves thinking and talking about the construct, and having experts write items that they think would do well in eliciting information about the construct.\index{assessment development!deductive approach}
The measure developer deduces from the construct which items to use.\index{assessment development!deductive approach}
Therefore, the deductive approach completely depends on our ability to understand a given construct and translate this understanding to the generation of item content that will be understood by the examinees in such a way that it elicits accurate ratings for the construct of interest.\index{assessment development!deductive approach}
Most assessments are developed using the deductive approach.\index{assessment development!deductive approach}

#### Pros {#deductiveApproachPros}

There are several pros of using the deductive approach to develop measures:\index{assessment development!deductive approach}

- Using the deductive approach is fast, easy, and short.\index{assessment development!deductive approach}
Generating such scales requires few people, and is often fast and accurate.\index{assessment development!deductive approach}
It does not typically take as much time to develop a measure using the deductive approach.\index{assessment development!deductive approach}
Moreover, it allows the possibility of short scales that are quick to administer.
By contrast to short scales developed by the deductive approach, the [MMPI](#mmpi) (developed using the [external approach](#externalApproach)) is very long.\index{assessment development!deductive approach}\index{assessment development!external approach}\index{Minnesota Multiphasic Personality Inventory}
- Measures developed (well) using the deductive approach are always [content valid](#contentValidity) because of the reliance on theory—items tend to be prototypical of the construct.\index{assessment development!deductive approach}\index{validity!content}\index{theory}
- Measures developed using the deductive approach are usually [face valid](#faceValidity), more likely than [external approach](#externalApproach).\index{assessment development!deductive approach}\index{assessment development!external approach}\index{validity!face}
[Face validity](#faceValidity) is often an advantage, but not always.\index{assessment development!deductive approach}\index{validity!face}
[Face validity](#faceValidity) can help with disseminability because others may be more likely to adopt it if it appears to assess what it claims to assess.\index{assessment development!deductive approach}\index{validity!face}
However, [face validity](#faceValidity) is not desirable when trying to prevent faking good or faking bad.\index{assessment development!deductive approach}\index{validity!face}\index{faking!good}\index{faking!bad}
- Measures developed using the deductive approach tend to have better communicability—i.e., how comprehensible the information communicated is to the examiner based on the responses.\index{assessment development!deductive approach}

#### Cons {#deductiveApproachCons}

There are also cons of using the deductive approach to develop measures:\index{assessment development!deductive approach}

- If your theory or understanding is wrong, your scale will be wrong!\index{assessment development!deductive approach}\index{theory}
- Additionally, if the construct itself is vague, and there is overlap between constructs, scales may be difficult to differentiate between them, making it difficult to establish [discriminant validity](#discriminantValidity).\index{assessment development!deductive approach}\index{validity!discriminant}
Many theories and constructs overlap.\index{assessment development!deductive approach}\index{theory}
Therefore, measures often overlap—even measures with very different names!\index{assessment development!deductive approach}
For example, consider the Rosenberg Self-Esteem Scale and the Spielberger State-Trait Anxiety Inventory:\index{assessment development!deductive approach}

Items on the Rosenberg Self-Esteem Scale include:\index{assessment development!deductive approach}

- "At times I think I am no good at all."\index{assessment development!deductive approach}
- "I certainly feel useless at times."\index{assessment development!deductive approach}
- "On the whole, I am satisfied with myself."\index{assessment development!deductive approach}

Items on the Spielberger State–Trait Anxiety Inventory (STAI):\index{assessment development!deductive approach}

- "I lack self-confidence"\index{assessment development!deductive approach}
- "I feel inadequate"\index{assessment development!deductive approach}
- "I feel satisfied with myself"\index{assessment development!deductive approach}

### Inductive Approach to Scale Construct {#inductiveApproach}

The inductive approach to developing a personality measure is also called an internal or item-metric approach.\index{assessment development!inductive approach}
The inductive approach is an empirical, data-driven approach for scale construction, in which scales are derived from the pre-existing internal associations between items.\index{assessment development!inductive approach}\index{empiricism}
A large pool of items is selected, and scales are generated from the item pools based on the structure of the internal association between items.\index{assessment development!inductive approach}
The inductive approach assumes that universal laws exist for personality structure, that is, that there is a natural structure.\index{assessment development!inductive approach}
The hope is that personality has simple structure: that each item loads onto (i.e., reflects) one and only one factor.\index{assessment development!inductive approach}\index{simple structure}
It is the hope of the inductive approach that there is simple structure because it makes the natural structure easier to detect using available methods.\index{assessment development!inductive approach}\index{simple structure}

The inductive approach is empirical because the answers comes from within the data.\index{assessment development!inductive approach}
But the inductive approach differs from the [external approach](#externalApproach).\index{assessment development!inductive approach}\index{assessment development!external approach}
In the inductive approach, the data come from the internal structure of the measure's items.\index{assessment development!inductive approach}
The empirical approach is also based on empirical data.\index{assessment development!empirical approach}
Science involves prediction and both the inductive and empirical approach use prediction.\index{assessment development!inductive approach}\index{assessment development!empirical approach}
The empirical approach examines how items predict some external criterion.\index{assessment development!empirical approach}\index{criterion}
By contrast, the inductive approach examines how items predict or relate to each other.\index{assessment development!inductive approach}
The goal of the inductive approach is to to "describe nature at its joints."\index{assessment development!inductive approach}

According to the inductive approach, once you understand constructs, you can understand how they are connected to each other.\index{assessment development!inductive approach}
The [external approach](#externalApproach) does not really care about the items themselves.\index{assessment development!external approach}
In the inductive approach, you need to use theoretical knowledge to interpret findings.\index{assessment development!inductive approach}
The [deductive approach](#deductiveApproach) uses theory up front to make the scale.\index{assessment development!deductive approach}
The inductive approach concerns itself with the items and what inferences can be made.\index{assessment development!inductive approach}
The method helps group the large set of items into subscales based on clusters of items that covary most strongly with each other using [factor analysis](#factorAnalysisOverview), and it drops items with a low [item–total correlation](#itemTotalCorrelation-reliability), factor loading, or [discrimination parameter](#itemDiscrimination).\index{assessment development!inductive approach}\index{reliability!internal consistency!average item–total correlation}

[Factor analysis](#factorAnalysisOverview) is used is used for the inductive approach to developing measures.\index{assessment development!inductive approach}\index{factor analysis}
It is used to evaluate the internal structure of a measure, and ideally, the structure of a construct.\index{assessment development!inductive approach}
Factor analysis is considered to be a "pure" data-driven method for structuring data, but as noted in Section \@ref(factorAnalysisDecisions), the "truth" that we get depends heavily on the decisions we make regarding the parameters of our factor analysis.\index{assessment development!inductive approach}\index{factor analysis}\index{factor analysis!decisions}
In sum, [factor analysis](#factorAnalysisOverview) is not purely inductive because the result is influenced by many decisions by the investigator.\index{assessment development!inductive approach}\index{factor analysis}\index{factor analysis!decisions}
Even though the inductive approach ([factor analysis](#factorAnalysisOverview)) is empirical, theory and interpretability should also inform decisions.\index{assessment development!inductive approach}\index{theory}\index{empiricism}

#### Pros {#inductiveApproachPros}

There are several pros of using the inductive approach to develop measures:\index{assessment development!inductive approach}

- The inductive approach yields estimates of associations between items and can arrive at estimates of a simple, homogeneous construct.\index{assessment development!inductive approach}
- You do not need to know much to use the inductive approach (relative to the [deductive approach](#deductiveApproach)): just use the items you have and use a data reduction approach.\index{assessment development!inductive approach}\index{assessment development!deductive approach}
- The inductive approach can derive short, homogeneous scales.\index{assessment development!inductive approach}
Then, you can see how constructs relate to other constructs.\index{assessment development!inductive approach}
- The inductive approach is a "purer" method of scale construction because it relies on the natural structure of the data, and no theoretical knowledge or validation to a [criterion](#criterionValidity) is required on the front end of scale development.\index{assessment development!inductive approach}\index{theory}\index{validity!criterion}
- The data are allowed to "speak for themselves."\index{assessment development!inductive approach}\index{empiricism}

#### Cons {#inductiveApproachCons}

There are also cons of using the inductive approach to develop measures:\index{assessment development!inductive approach}

- The inductivists (i.e., users of the inductive approach) hope that a simple structure exists within a set of items and that this structure can meaningfully differentiate between constructs.\index{assessment development!inductive approach}\index{simple structure}
If there is no simple structure, interpretations of scales that emerge can be difficult.\index{assessment development!inductive approach}\index{simple structure}
- In addition, this approach is not "pure" because the structure we get depends on the analysis decisions we make.\index{assessment development!inductive approach}\index{factor analysis!decisions}
The answers you get depend on the decisions you make, and there really is no basis on which to make decisions.\index{assessment development!inductive approach}\index{factor analysis!decisions}
This is called indeterminacy.\index{assessment development!inductive approach}\index{factor analysis!decisions}\index{factor analysis!indeterminacy}
There are a number of decisions in [factor analysis](#factorAnalysisOverview), including decisions such as the number of factors and the nature of factors—i.e., how to interpret them.\index{assessment development!inductive approach}\index{factor analysis!decisions}\index{factor analysis!indeterminacy}
- [Factor analysis](#factorAnalysisOverview) is not straightforward, and depends on decisions made along the way.\index{assessment development!inductive approach}\index{factor analysis!decisions}
Therefore, some argue because so much is in the hands of the investigator that [factor analysis](#factorAnalysisOverview) is really a semi-empirical approach.\index{assessment development!inductive approach}\index{factor analysis!decisions}\index{empiricism}
- SPSS likely contributes to the problem because it makes so many decisions for you, and many have no idea what they are doing!\index{assessment development!inductive approach}\index{factor analysis!decisions}
SPSS is for ease of use, but it is limiting.\index{assessment development!inductive approach}\index{factor analysis!decisions}
In SPSS, you can use [principal component analysis (PCA)](#pcaOverview) for item extraction.\index{assessment development!inductive approach}\index{factor analysis!decisions}\index{principal component analysis}
Investigators often determine how many components/factors to keep based on the [criterion](#criterionValidity) of keeping components with eigenvalues greater than one, often use orthogonal rotation of data, etc.\index{assessment development!inductive approach}\index{factor analysis!decisions}\index{eigenvalue}
[Factor analysis](#factorAnalysisOverview) and [PCA](#pcaOverview) are described in Chapter \@ref(factor-analysis-PCA).\index{factor analysis}\index{principal component analysis}

### Hybrid Approach {#hybridApproach}

The preceding discussion described the three primary approaches to developing objective personality measures.\index{assessment development!approaches to}
However, the approaches can be mixed.\index{assessment development!approaches to}
For instance, once could write a large set of items based on theory (i.e., the [deductive approach](#deductiveApproach)) and then pick items to keep based on their [criterion-related validity](#criterionValidity) (i.e., the [external approach](#externalApproach)), and group them into scales based on their internal structure (i.e., the [inductive approach](#inductiveApproach)).\index{assessment development!deductive approach}\index{assessment development!external approach}\index{assessment development!inductive approach}\index{validity!criterion}
There is not strong evidence for the superiority of any of the approaches compared to the others.\index{assessment development!approaches to}

## Measure Development and Item Selection {#measureDevelopment}

Despite not having strong evidence for the superiority of any of the approaches to scale construction, best practices to measure development include:\index{assessment development!best practices}

- Start with theory to define the construct and create item pools, using a [deductive approach](#deductiveApproach).\index{assessment development!best practices}\index{assessment development!deductive approach}\index{theory}
    - Be inclusive at this stage.\index{assessment development!best practices}\index{assessment development!deductive approach}
Create more items than you will actually use—even if items are only tangentially related—so you have a broad pool of items.\index{assessment development!best practices}\index{assessment development!deductive approach}
    - Include items of other constructs to establish the boundaries of the construct, i.e., [discriminant validity](#discriminantValidity).\index{assessment development!best practices}\index{assessment development!deductive approach}\index{validity!discriminant}
- Then, test these item pools, and consider their empirical relations to revise and/or drop items.\index{assessment development!best practices}\index{assessment development!deductive approach}\index{assessment development!external approach}\index{assessment development!inductive approach}
Ideally, you would test the items in large and heterogeneous samples that are representative of the population.\index{assessment development!best practices}\index{validity!external}
    - Examine the items in relation to external [criteria](#criterionValidity), using an [empirical approach](#external approach).\index{assessment development!best practices}\index{assessment development!external approach}\index{criterion}
    - And examine items in relation to each other, using an [inductive approach](#inductiveApproach).\index{assessment development!best practices}\index{assessment development!inductive approach}
This likely involves [factor analysis](#factorAnalysisOverview) and/or [item response theory](#irt).\index{assessment development!best practices}\index{factor analysis}\index{item response theory}
        - We want items, collectively, to span the full range of [difficulty/severity](#itemDifficulty) of the construct in the target range of interest.\index{assessment development!best practices}\index{item response theory!item difficulty}
It is important for the items to have accuracy (i.e., strong [discrimination](#itemDiscrimination) and [information](#irtReliability)) in the target range of interest on the construct (e.g., low, medium, and/or high).\index{assessment development!best practices}\index{item response theory!item discrimination}\index{item response theory!information}
The target range of interest depends on the purpose of the assessment, as described in Section \@ref(goodMeasure).\index{assessment development!best practices}
For example, items used for diagnosis should focus on higher levels of the construct, whereas items used for screening should identify those with elevated risk but might not need to discriminate at higher levels.\index{assessment development!best practices}\index{diagnosis}\index{screening}
For assessing individual differences, you would want items that discriminate across the full range, including at the lower end.\index{assessment development!best practices}
        - Items should show some [internal consistency](#internalConsistency-reliability), as evidenced by an [inter-item](#interItemCorrelation-reliability) or [item–total](#itemTotalCorrelation-reliability) correlation, but items should not be too highly inter-correlated.\index{assessment development!best practices}\index{reliability!internal consistency}\index{reliability!internal consistency!average inter-item correlation}\index{reliability!internal consistency!average item–total correlation}
If items are too highly correlated, they are redundant and do not provide unique information.\index{assessment development!best practices}\index{reliability!internal consistency!average inter-item correlation}
Inter-item correlations should only be moderate, e.g., should range from approximately .15 to .50.\index{assessment development!best practices}\index{reliability!internal consistency!average inter-item correlation}
But items should be highly correlated with the latent factor representing the target construct.\index{assessment development!best practices}\index{latent variable}\index{structural equation modeling!factor loading}\index{item response theory!item discrimination}
That is, the items should have a high [discrimination](#itemDiscrimination) or a strong factor loading.\index{assessment development!best practices}\index{structural equation modeling!factor loading}\index{item response theory!item discrimination}
- Then, interpret the results and label the factors based on theory.\index{assessment development!best practices}\index{theory}
- Evaluate multiple aspects of [reliability](#reliability) and [validity](#validity) of the scale.\index{assessment development!best practices}\index{reliability}\index{validity}

Other ideas in scale development are discussed by @Burisch1984, @Clark1995, @Clark2019, and @Loevinger1957.\index{assessment development!best practices}

### The Response Scale {#responseScale}

Evidence suggests that there may not benefits of having more than six response options for likert-scale items that assess personality [@Simms2019].\index{personality assessment}\index{response scale!precision of}\index{Likert scale}

## Emerging Techniques {#emergingTechniques-personality}

One emerging technique for developing personalized models of personality is the group iterative multiple model estimation (GIMME) model [@Wright2019b], as described in Section \@ref(nomotheticIdiographicApproaches).\index{personality assessment}\index{group iterative multiple model estimation}\index{idiographic}

## The Flawed Nature of Self-Assessments {#flawedSelfAssessment}

It is a common finding that people tend to over-estimate their skill and abilities—most people tend to describe themselves as "above average", which is statistically impossible.\index{self-report}
People are over-confident, and they over-estimate the likelihood of achieving desirable outcomes and underestimate how long it will take to complete future projects.\index{self-report}\index{over-confidence}
Self-report is only weakly associated with people's actual behavior.\index{self-report}

There are there prominent ways in which self-assessment have been shown to be flawed:\index{self-report}

- response [bias](#bias)\index{self-report}\index{bias}\index{response style}
- ambiguity of items\index{self-report}
- lack of insight by people to rate themselves\index{self-report}

### Response Bias {#bias-personality}

One way that self-assessment has been shown to be flawed is in terms of [response bias](#bias).\index{self-report}\index{bias}\index{response style}
[Bias](#bias) involves a [systematic measurement error](#systematicError).\index{bias}\index{response style}\index{measurement error!systematic error}
For instance, it is not uncommon for participants to fake good or fake bad on assessments due to situational reasons or due to how questions are worded.\index{self-report}\index{faking!good}\index{faking!bad}
When answering questions, many people desire to seem better than they are.\index{self-report}\index{faking!good}\index{bias!social desirability}
This phenomenon is called social desirability bias, which is a form of [method bias](#types-of-method-biases) in which people systematically adjust their responses to reflect more socially desirable attributes.\index{self-report}\index{faking!good}\index{bias!social desirability}\index{method bias}
The degree of a person's faking has been shown to be related to social desirability bias [@Bensch2019].\index{self-report}\index{faking!good}\index{bias!social desirability}
If you want to want to know the true prevalence of a given behavior, you can deal with social desirability bias using a [randomized response model](#randomizedResponseModel), as described in Section \@ref(randomizedResponseModel).\index{self-report}\index{faking!good}\index{bias!social desirability}\index{randomized response model}
There are indicators of response bias that are worth considering [@Burchett2019].\index{self-report}\index{bias}\index{response style}

### Ambiguity of Items {#itemAmbiguity}

Another way that self-assessment has been shown to be flawed is in the ambiguity of items.\index{self-report}
People tend to have a difficult time providing an accurate characterizations of their skills on tasks that are poorly defined or ambiguous.\index{self-report}
For example, what does it mean to be a "warm" parent?\index{self-report}
Beyond this, even the language on self-assessments can be highly ambiguous.\index{self-report}
For example, how often is "rarely"?\index{self-report}
Such questions can systematically skew answers to self-assessments.\index{self-report}

### Lack of Insight by People to Rate Themselves {#lackOfInsight}

A third way that self-assessment has been shown to be flawed is due to respondents' lack of insight into the required information to make good self-assessments.\index{self-report}
People often make poor judgments because they lack the required skills and information necessary to have insight into their actual performance, or they neglect it when it is available.\index{self-report}
The lack of insight into poor judgments can also be caused by errors of omission—in which they do not know that they have made a mistake because they do not know what the best alternative would have been.\index{self-report}
Also, people infrequently get feedback from others on the constructs we are attempting to assess—as a result, their self-views are not informed by objective feedback.\index{self-report}

### Ways to Improve Self-Assessment {#improveSelfAssessment}

Ways to improve self-assessment are described by [@Dunning2004]:\index{self-report!ways to improve}

- Use clear items that are behaviorally specific\index{self-report!ways to improve}
- Provide frequent, timely, objective, and individualized feedback\index{self-report!ways to improve}
- Use self-testing, after a delay after studying\index{self-report!ways to improve}
- Review one's past performance\index{self-report!ways to improve}
- Use peer assessment\index{self-report!ways to improve}
- Target the motivational basis of the over-confidence\index{self-report!ways to improve}\index{over-confidence}
- Benchmark—compare one's performance against others' performance\index{self-report!ways to improve}
- Introduce "desirable difficulties" to instruction, such as spreading training over several sessions and varying the circumstances of the training.\index{self-report!ways to improve}
These challenges can harm the speed that students learn but leaves them better able to retain what they learned and to transfer it to new situations in the future.\index{self-report!ways to improve}
- To account for over-confidence, add in safety factors and buffer time.\index{self-report!ways to improve}\index{over-confidence}
For instance, add 30%–50% extra time to all time completion estimates for projects.\index{self-report!ways to improve}\index{over-confidence}

### Satisficing (Versus Optimizing) {#satisficing}

There have been new developments in gaining insight into the cognitive processes by which respondents generate answers to survey questions [@Krosnick1999].\index{satisficing}\index{optimizing}

#### Optimizing {#optimizing}

*Optimizing* involves a respondent responding optimally to a question—i.e., responding in an [unbiased](#bias) and thorough manner.\index{optimizing}\index{bias}
There are four cognitive steps or stages that respondents must complete to answer a question optimally:\index{optimizing}

1. They interpret the question\index{optimizing}
1. They search their memory for relevant information\index{optimizing}
1. They integrate all relevant information into a single judgment\index{optimizing}
1. They use that judgment to select a response\index{optimizing}

The complexity of the cognitive processes one must engage in when giving an optimal answer requires a lot of cognitive effort.\index{optimizing}
Giving such effort can happen for a variety of reasons: desire of self-expression, being altruistic, desire for gratification, etc.\index{optimizing}
The extent to which such motivations inspire a person to engage in the cognitive requirements to respond to questions in an [unbiased](#bias) and thorough manner is referred to as optimization.\index{optimizing}\index{bias}
Optimizing deals with how hard the person worked and how much they care about giving their best response.\index{optimizing}

#### Satisficing {#satisficingVsOptimizing}

If, for some reason, a person is not motivated to expend the cognitive effort required to make an optimal response, and instead settle for a satisfactory response, they are said to be *satisficing*.\index{satisficing}
That is, they are expending less effort that prevents obtaining the optimal answer.\index{satisficing}
There are two types of satisficing: weak satisficing and strong satisficing.\index{satisficing}
In *weak satisficing*, respondents execute all four cognitive steps, they are just less diligent about doing so, and they settle on selecting a satisfactory answer rather than the optimal answer.\index{satisficing}
Weak satisficing may lead to selecting earlier response options without careful evaluation of later response options, which is susceptible to confirmation bias.\index{satisficing}
In *strong satisficing*, a respondent skips the retrieval and judgment steps, interprets the question superficially and selects an answer based on what they think will be a reasonable (or "satisfactory") response.\index{satisficing}
Their answer is not reflective of a person's actual feelings about the construct of interest.\index{satisficing}
Answers could also be selected arbitrarily.\index{satisficing}

There are several conditions when satisficing is most likely to occur:\index{satisficing}

- The greater the task difficulty\index{satisficing}
- The lower the respondent's ability\index{satisficing}
- The lower the respondent's motivation\index{satisficing}
- When "No opinion" responses are an option\index{satisficing}

In sum, to reduce the likelihood of satisficing, match the task to the participant's ability, make sure they have motivation to respond correctly, and do not provide a "no opinion" response option.\index{satisficing}

## Observational Assessments {#observation-personality}

Given the challenges with self- and informant-report of personality, it can also be worth considering [observational assessments](#behavioral).\index{personality assessment}\index{observation}\index{self-report}
For example, one observational approach to assessing personality involves a "thin-slice" approach, in which observers briefly assess people's personality via observations across a range of situations or contexts [@Tackett2019b].\index{personality assessment}\index{observation}
Observational ratings of personality can then be combined with self- and informant-rated personality in a [multitrait-multimethod matrix](#MTMM) [@Tackett2019b].\index{personality assessment}\index{observation}\index{self-report}\index{informant report}\index{multitrait-multimethod matrix}

## Structure of Personality {#personalityStructure}

The most well-supported structure of personality is the five-factor model of personality.\index{personality!structure}\index{personality!five-factor model}
The highest-order dimensions of the five-factor model are defined by the Big Five.\index{personality!structure}\index{personality!five-factor model}
The Big Five are known by the acronym OCEAN: **O**penness to experience (versus closed-mindedness), **C**ontientiousness (versus disorganization), **E**xtraversion (versus intraversion), **A**greeableness (versus disagreeableness), and **N**euroticism (versus emotional stability).\index{personality!structure}\index{personality!five-factor model}

## Personality Across the Lifespan {#personalityAcrossTheLifespan}

As described by @Costa2019, individual differences (i.e., rank order) in personality are relatively stable from middle childhood to old age.\index{personality!stability}
On average, neuroticism tends to decline, and agreeableness and contientiousness tend to increase with age [@Costa2019].\index{personality!development}
It is unclear how extraversion and openness to new experiences change across the life span.\index{personality!development}

## Conclusion {#conclusion-objective-personality}

In an *objective personality test*, a stimulus is presented to a respondent, who makes a closed-ended response, such as True/False or Likert ratings.\index{personality assessment!objective}\index{Likert scale}
An example of an objective personality test is the [Minnesota Multiphasic Personality Inventory](#mmpi) (MMPI).\index{personality assessment!objective}\index{Minnesota Multiphasic Personality Inventory}
There are three primary approaches to developing personality measures and other scales.\index{assessment development!approaches to}
One is the [external approach](#externalApproach), in which items are selected based on their association with an external criterion.\index{assessment development!external approach}\index{criterion}
A second approach is the [deductive approach](#deductiveApproach), in which items are deduced based on theory.\index{assessment development!external approach}\index{theory}
A third approach is the [inductive approach](#inductiveApproach), in which items are selected based on the internal association between items that are intended to assess the same construct.\index{assessment development!inductive approach}
[Guidelines for measurement development](#measureDevelopment) are provided.\index{assessment development!best practices}
Nevertheless, relying on self-report and self-assessment is prone to key weaknesses including [response bias](#bias-personality), [ambiguity of items](#itemAmbiguity), [lack of insight](#lackOfInsight), and [satisficing](#satisficing).\index{self-report}\index{bias}\index{response style}\index{satisficing}\index{optimizing}
There are ways to [improve self-assessment](#improveSelfAssessment), but it can also be helpful to supplement self-assessments with informants' ratings and with [observational assessments](#observation-personality).\index{self-report}\index{observation}\index{informant report}\index{self-report!ways to improve}

## Suggested Readings {#readings-objective-personality}

@Burisch1984; @Dunning2004; @Krosnick1999
