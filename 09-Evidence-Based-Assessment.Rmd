# Evidence-Based Assessment {#evidence-based}

I was initially hesitant to include a chapter titled "evidence-based assessment" because this whole book is about doing assessment in the strongest, most scientifically supported (i.e., evidence-based) ways. However, I decided to include a chapter on evidence-based assessment to summarize many of the important considerations in ensuring our assessments are strong for their intended uses, especially in clinical psychology, and to discuss the value of some cutting-edge (and some not-so-cutting-edge) techniques to maximize the validity of inferences.

## Considerations

In general, we need to use assessment devices that are:

- clinically relevant: they inform decision making processes
- culturally sensitive: they are relevant to individuals from various backgrounds, especially the backgrounds in the population of interest
- scientifically sound: strong psychometrics (reliability and validity)

## Clinically Relevant

Effective treatment depends on accurate assessment. Thus, it is important to consider the [treatment utility of assessment](#treatmentUtility) to determine whether the assessment has value. Several study methods were designed to examine the treatment utility of assessment, including manipulated assessment (compares assessment versus no assessment) and manipulated use (compares use versus no use of data from the assessment for treatment matching).

It is also important to consider the ease of dissemination of an assessment: is it time- and money-efficient, especially in terms of its cost–benefit ratio? Brief assessments, computerized testing, and adaptive testing can help assessments be clinically practical. It should be straightforward to score and interpret. And it should provide [incremental validity](#incrementalValidity), i.e., additional useful information above and beyond what is gained by other assessment devices.

We have already discussed how assessments can yield more effective outcomes indirectly through matching the right treatment approach to the client. It is also worth noting, however, that assessments can also lead *directly* to improved treatment outcomes. Conducting an assessment is an intervention—it can have carryover effects, and can result in self-reflection, self-awareness, and reactivity, i.e., change due to observing it.

Assessment is also an important component of measurement-based care. Measurement-based care is the approach of treatment monitoring and modifying treatment accordingly. Assessment does not stop at the beginning of the treatment—it is continuous and ongoing. So, ongoing measurement is recommended throughout treatment so that the clinician can modify the treatment in response to measurements. Assessment of treatment progress needs to be sensitive to change, i.e., the assessment needs to show treatment sensitivity, and it needs to be actionable, i.e., it needs to have utility.

In clinical psychological assessment, it is important for assessments to consider co-occurrence of multiple issues (comorbidity) and differential diagnosis. It is important to accurately assess frequently conditions that frequently co-occur or covary (e.g., depression and anxiety) and to differentiate between multiple possibilities for what may explain the client's difficulties. It is valuable to pose alternative or competing hypotheses and test them to rule out other potential explanations. It is important to look for disconfirming evidence, not just evidence that confirms one's suspicions. It is also valuable to consider assessments from multiple informants (e.g., parents, teachers, peers) and multiple levels of analysis, including biological, psychological, and social-contextual factors. It is also important to consider functional impairment and not just diagnostic status.

[Which chapter should I put this in?: DSM-based disorders are fictive categories etc. Doesn't carve nature at its joints etc. Dimensional > categorical, etc.]

## Culturally Sensitive

It is important to mitigate cultural bias of instruments. It is important for the measure to be useful across the population of interest. To accomplish this, one may have to modify an assessment approach to account for clinically significant moderating variables. We discuss culturally sensitive assessment more in Chapter \@ref(diversity).

## Scientifically Sound

The development and selection of measures should be based on scientifically supported theories in psychopathology and basic psychological science. Measures should be standardized, with similar procedures across participants, clients, and examiners.

Reliability and validity of measures' scores are specific to a particular use of the test, and are specific for a given population and context. So, it is important to clearly specify the purpose of the assessment. As just a few examples, the purpose of the assessment could be screening for early identification of risk, for diagnosis, for treatment monitoring, for treatment evaluation, or for measuring a phenomenon of interest in research. In general, the purposes of an assessment can be summarized into the 3 Ps [@Youngstrom2017]: predict, prescribe, and process. The purpose of an assessment is to predict if the purpose is to relate an assessment to a criterion at a later point in time. An assessment is used to prescribe if it informs decision making about the participant or client—for example, a decision about which treatment to give, identifying moderators of treatment effectiveness, or specifying potential confounds or alternative explanations that would warrant a different treatment. An assessment is used to understand process if it informs understanding of the participant or client—for example, identifying mediators of treatment effectiveness or tracking treatment progress.

Whichever the purpose of the assessment, it is important to test and evaluate the psychometrics of the assessment device for that particular purpose. Only use the assessment device in a test battery if it advances that purpose. @Youngstrom2017 describe the different core psychometric features that are especially relevant for each purpose. For instance, predictive and discriminative validity are crucial for prediction, whereas inter-rater reliability is crucial for prescription, and treatment sensitivity is crucial for understanding process.

### Standard for Excellent Tests

Additionally, when making norm-references judgments, it is important that the assessment has appropriate norms and evidence of accuracy for any cut-scores (e.g., diagnostic thresholds). Per @Youngstrom2017, below are the norms and psychometric standards for excellent tests:

- If the assessment has norms, the norms provide a mean and standard deviation for the total score (and any subscores) that were determined from multiple, large samples that are representative of the populations to which it is intended for the test to be administered.
- Internal consistency: greater than .90 based on Cronbach's alpha or (better yet) omega
- Inter-rater reliability: Cohen's kappa $\ge$ .85; intra-class correlation $\ge$ .90
- Test–retest reliability: If the construct is stable, the measure shows stability of individual differences and repeatability. However, note that not all constructs are expected to be stable. For stable constructs, the measure should show stability of individual differences (i.e., relative or rank-order stability): $r\text{s} \ge .70$ over a year or longer. For stable constructs, the measure should also show repeatability, i.e., absolute stability in level: A Bland–Altman plot and corresponding regression shows no significant bias or trends, and the repeatability coefficient (also known as Smallest Real Difference, SRD, or limits of agreement, LOA) is small.

[**Ursenbach et al, 2019 citation**]

As presented in Equation \@ref(eq:bayes5), the posttest (or posterior) odds are equal to the [pretest odds](#pretestOdds) multiplied by the [likelihood ratio](#positiveLikelihoodRatio). Bayes' theorem is discussed in Section \@ref(bayesTheorem). Using this formula, and converting odds to probabilities, we can use a Fagan probability nomogram to determine the [posttest probability](#posttestProbability) following a test result. The calculation of posttest probability is described in Section \@ref(posttestProbability). A *probability nomogram* is a way of visually applying [Bayes' theorem](#bayesTheorem) to determine the posttest probability of having a condition based on the pretest (or prior) probability and likelihood ratio. To use a probability nomogram, connect the dots from the starting probability (left line) with the likelihood ratio (middle line) to see the updated probability. The updated (posttest) probability is where the connecting line crosses the third, right line.

```{r probabilityNomogram, out.width = "100%", fig.align = "center", fig.cap = "Probability Nomogram. Figure retrieved from [https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Fagan_nomogram.svg/945px-Fagan_nomogram.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Fagan_nomogram.svg/945px-Fagan_nomogram.svg.png)", echo = FALSE}
knitr::include_graphics("./Images/probabilityNomogram.png")
```

For instance, if the starting probability is .5% and the likelihood ratio is 10 (e.g., sensitivity = .90, specificity = .91: $\text{likelihood ratio} = \frac{\text{sensitivity}}{1 - \text{specificity}} = \frac{.9}{1-.91} = 10$), the updated probability is less than 5%. The formula and function for computing posttest probability are provided in Section \@ref(posttestProbability).

```{r}
posttestProbability(pretestProb = .005, likelihoodRatio = 10)
```

```{r probabilityNomogramLine, out.width = "100%", fig.align = "center", fig.cap = "Probability Nomogram Example. Figure adapted from [https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Fagan_nomogram.svg/945px-Fagan_nomogram.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Fagan_nomogram.svg/945px-Fagan_nomogram.svg.png)", echo = FALSE}
knitr::include_graphics("./Images/probabilityNomogramLine.png")
```

## Conclusion
