# Scores and Scales

Assessments yield information. The information is encoded in scores or in other types of data. It is important to consider the different types of data because the types of data restrict what options are available to analyze the data.

## Getting Started

Applied examples in R are provided below. Each chapter that has R examples in this book has a section on "Getting Started" which provides the code to load relevant libraries, load data files, simulate data, add missing data, conduct calculations, and more.

### Load Libraries

```{r, message = FALSE, warning = FALSE}
library("dplyr")
library("tidyverse")
library("tinytex")
library("knitr")
library("rmarkdown")
library("bookdown")
```

### Prepare Data

#### Simulate Data

For reproducibility, I set the seed below. Using the same seed will yield the same answer every time. There is nothing special about this particular seed.

```{r}
set.seed(52242)

rawData <- rnorm(n = 1000, mean = 200, sd = 30)

scores <- data.frame(rawData = rawData)
```

#### Add Missing Data

Adding missing data to dataframes helps make examples more realistic to real-life data, and helps you get in the habit of programming to account for missing data.

```{r}
scores$rawData[c(5,10)] <- NA
```

## Data Types

There are four general data types: nominal, ordinal, interval, and ratio. Depending on the use of the variable, the data could fall into more than one category. The type of data influences what kinds of data analysis you can do. For instance, parametric statistical analysis (e.g., *t*-test, analysis of variance [ANOVA], and linear regression) assumes that data are interval or ratio.

### Nominal

Nominal data are distinct categories. They are categorical and unordered. Nominal data make no quantitative claims. Nominal data represent things that we can name (e.g., cat and dog). Nominal data can be represented with numbers. For example, zipcodes are nominal. Numbers that represent a participant's sex, race, or ethnicity are also nominal. Higher numbers of nominal data do not reflect higher (or lower) levels of the construct because they numbers represent categories that do not have an order.

### Ordinal

Ordinal data are ordered categories: they have a name and an order. They make no claim about the conceptual distance between the ranks, only that higher values represent higher (or lower) levels of the construct. For example, ranks following a race are ordinal, that is, the person with rank 1 finished before the person with rank 2, who finished before the person with rank 3 (1 > 2 > 3 > 4). Ordinal data make a limited claim because the conceptual distance between adjacent numbers is not the same. For instance, the person who finished the race first might have finished 10 minutes before the second-place finisher; whereas the 3rd-place finisher might have finished 1 second after the second-place finisher.

That is, just because the numbers have the same *mathematical* distance does not mean that they represent the same *conceptual* distance on the construct. For example, if the respondent is asked how many drinks they had in the past day, and the options are 0 = 0 drinks; 1 = 1–2 drinks; 2 = 3 or more drinks, the scale is ordinal. Even the numbers have the same mathematical distance (1, 2, 3), they do not represent the same conceptual distance. Most data in psychology are ordinal data even though they are often treated as if they were interval data.

### Interval

Interval data are ordered and have meaningful distances (i.e., equal spacing between intervals). You can sum interval data (e.g., 2 is 2 away from 4), but you cannot multiply interval data ($2 \times 2 \ne 4$). Examples of interval data are temperature in Fahrenheit and Celsius—100 degrees Fahrenheit is not twice as hot as 50 degrees Farhenheit. Years of education is interval, whereas educational attainment (e.g., high school degree, college degree, graduate degree) is only ordinal. Although much data in psychology involves numbers that have the same mathematical distance between intervals, the intervals likely do not represent the same conceptual distance. For example, the difference in severity of two people who have two symptoms and four symptoms of depression, respectively, may not be the same difference in depression severity as two people who have four symptoms and six symptoms, respectively.

### Ratio

Ratio data are ordered, have meaningful distances, and have a true (absolute) zero that represents absence of the construct. With ratio data, multiplicative relationships are true. An example of ratio data are temperature in Kelvin—100 degrees Kelvin is twice as hot as 50 degrees Kelvin. There is a dream of having ratio scales in psychology, but we still do not have a true zero with psychological constructs—what does total absence of depression mean (apart from a dead person)?

## Score Transformation

There are a number of score transformations, depending on the goal. Some score transformations (e.g., log transform) seek to make data more normally distributed to meet assumptions of particular analysis approaches. Score transformations alter the original (raw) data. If you change the data, it can change the results. Score transformations are not neutral.

### Raw Scores

Raw scores are the original data, or they may be aggregations (e.g., sums or means) of multiple items. Raw scores are the most pure because they are closest to the original operation (e.g., behavior). A disadvantage of raw scores is they are scale-dependent, and therefore may not be comparable across different measures with different scales.

```{r rawScores, fig.align = "center", out.width = "100%", fig.cap = "Histogram of Raw Scores"}
hist(scores$rawData, xlab = "Raw Scores", main = "Histogram of Raw Scores")
```

### Norm-Referenced Scores {#norm}

Norm-referenced scores are scores that are referenced to some norm. A norm is a standard of comparison. For instance, you may be interested in how well a participant performed relative to other children of the same sex, age, grade, or ethnicity. However, interpretation of norm-referenced scores depends on the measure and on the normative sample. A person's norm-referenced score can vary widely depending on which norms are used. Which reference group should you use? Age? Sex? Age and sex? Grade? Ethnicity? The optimal reference group depends on the purpose of the assessment. Pros and cons of group-based norms are discussed in Section \@ref(withinGroupNorming).

A standard normal distribution on various norm-referenced scales is depicted in Figure \@ref(fig:normedDistribution), as adapted from @Bandalos2018.

```{r normedDistribution, echo = FALSE, message = FALSE, results = "hide", out.width = "100%", fig.cap = "Various norm-referenced scales"}
standardNormal <- data.frame(zScore = -4:4)
standardNormal$Tscore <- seq(from = 10, to = 90, by = 10)
standardNormal$standardScore <- seq(from = 40, to = 160, by = 15)
standardNormal$cumulativePercent <- substr(as.character(pnorm(standardNormal$zScore) * 100), 1, 4)
standardNormal$cumulativePercentFigure <- c("0","0.1","2.3","15.9","50","84.1","97.7","99.9","100")

standardNormal$nonCumulativePercent[1] <- round((pnorm(-3) - pnorm(-4)) * 100, 2)
standardNormal$nonCumulativePercent[2] <- round((pnorm(-2) - pnorm(-3)) * 100, 2)
standardNormal$nonCumulativePercent[3] <- round((pnorm(-1) - pnorm(-2)) * 100, 2)
standardNormal$nonCumulativePercent[4] <- round((pnorm(0) - pnorm(-1)) * 100, 2)
standardNormal$nonCumulativePercent[5] <- round((pnorm(1) - pnorm(0)) * 100, 2)
standardNormal$nonCumulativePercent[6] <- round((pnorm(2) - pnorm(1)) * 100, 2)
standardNormal$nonCumulativePercent[7] <- round((pnorm(3) - pnorm(2)) * 100, 2)
standardNormal$nonCumulativePercent[8] <- round((pnorm(4) - pnorm(3)) * 100, 2)

standardNormal$nonCumulativePercentFigure <- paste(standardNormal$nonCumulativePercent, "%", sep = "")
standardNormal$midpointsZ <- c(-3.5,-2.5,-1.5,-0.5,0.5,1.5,2.5,3.5,NA)

standardNormal$nonCumulativePercent[9] <- NA
standardNormal$nonCumulativePercentFigure[9] <- NA

standardNormalPercentiles <- data.frame(percentileRank = c(1,5,10,20,30,40,50,60,70,80,90,95,99))
standardNormalPercentiles$percentileRankZ <- qnorm(standardNormalPercentiles$percentileRank / 100)

standardNormalStanines <- data.frame(stanine = 1:9)
standardNormalStanines$staninePercent <- c("4%","7%","12%","17%","20%","17%","12%","7%","4%")
standardNormalStanines$stanineCumulativeStartingPercent <- c(0,4,11,23,40,60,77,89,96)
standardNormalStanines$stanineCumulativeEndingPercent <- c(4,11,23,40,60,77,89,96,100)
standardNormalStanines$stanineCumulativeStartingPercentZ <- qnorm(standardNormalStanines$stanineCumulativeStartingPercent/100)
standardNormalStanines$stanineCumulativeEndingPercentZ <- qnorm(standardNormalStanines$stanineCumulativeEndingPercent/100)
standardNormalStanines[standardNormalStanines == -Inf] <- -4
standardNormalStanines[standardNormalStanines == Inf] <- 4
standardNormalStanines$midpointsZ <- rowMeans(standardNormalStanines[,c("stanineCumulativeStartingPercentZ","stanineCumulativeEndingPercentZ")])

par(xpd = NA,
    mgp = c(3, 0.5 , 0), # gap between axis label and axis
    mar = c(12, 7, 0, 0) + 0.1) # plot margins: default of the form c(bottom, left, top, right): c(5, 4, 4, 2) + 0.1
x <- seq(-4, 4, length = 10000)
y <- dnorm(x, mean = 0, sd = 1)

plot(x, y, type = "l", lwd = 8, axes = FALSE, xlab = NA, ylab = NA)

segments(x0 = -4, y0 = 0, y1 = 1)
segments(x0 = -3, y0 = 0, y1 = 1)
segments(x0 = -2, y0 = 0, y1 = 1)
segments(x0 = -1, y0 = 0, y1 = 1)
segments(x0 = 0, y0 = 0, y1 = 1)
segments(x0 = 1, y0 = 0, y1 = 1)
segments(x0 = 2, y0 = 0, y1 = 1)
segments(x0 = 3, y0 = 0, y1 = 1)
segments(x0 = 4, y0 = 0, y1 = 1)

axis(side = 1, at = standardNormal$zScore, pos = 0)
axis(side = 1, at = standardNormal$zScore, pos = -.06, labels = standardNormal$Tscore)
axis(side = 1, at = standardNormal$zScore, pos = -.12, labels = standardNormal$standardScore)
axis(side = 1, at = standardNormal$zScore, pos = -.18, labels = standardNormal$cumulativePercentFigure)
axis(side = 1, at = standardNormalPercentiles$percentileRankZ, pos = -.24, labels = standardNormalPercentiles$percentileRank, cex.axis = 0.5)

rect(xleft = standardNormalStanines$stanineCumulativeStartingPercentZ, ybottom = -.36, xright = standardNormalStanines$stanineCumulativeEndingPercentZ, ytop = -.31)
mtext(standardNormalStanines$stanine, side = 1, line = 9, at = standardNormalStanines$midpointsZ)

text(0.05, .02, labels = "Standard Deviations")
text(standardNormal$midpointsZ, .06, labels = standardNormal$nonCumulativePercentFigure)

mtext("Percent of cases \n under segment of \n the normal curve", side = 2, line = 0, at = .05, las = 1)
mtext("z-scores", side = 2, line = 0, at = -.033, las = 1)
mtext("T-scores", side = 2, line = 0, at = -.0934, las = 1)
mtext("Standard scores", side = 2, line = 0, at = -.1538, las = 1)
mtext("Cumulative percent", side = 2, line = 0, at = -.2142, las = 1)
mtext("Percentile ranks", side = 2, line = 0, at = -.2746, las = 1)
mtext("Stanines", side = 2, line = 0, at = -.335, las = 1)
```

#### Percentile Ranks

Percentile ranks reflect what percent of people the person scored higher than. Percentile ranks are frequently used for tests of intellectual/cognitive ability, academic achievement, academic aptitude, and grant funding. They seem like interval data, but they are not intervals because the conceptual spacing between the numbers is not equal. The difference in ability for two people who scored at the 99th and 98th percentile, respectively, is not the same as the difference in ability for two people who scored at the 49th and 50th percentile, respectively. Percentile ranks are only judged against a baseline; there is no subtraction.

Percentile ranks have unusual effects. There are lots of people in the middle of a distribution, so a very small difference in raw scores gets expanded out in percentiles. For instance, a raw score of 20 may have a percentile rank of 50, but a raw score of 24 may have a percentile rank of 68. However, a larger raw score change at the ends of the distribution may have a smaller percentile change. For example, a raw score of 120 may have a percentile rank of 97 whereas a raw score of 140 may have a percentile rank of 99.  Thus, percentile ranks stretch out differences for some people but constrict differences for others.

Here is an example of how to calculate percentile ranks using the `dplyr` package from the `tidyverse` [@R-tidyverse; @tidyverse2019]:

```{r}
scores$percentileRank <- percent_rank(scores$rawData) * 100
```

```{r percentileRanks, fig.align = "center", out.width = "100%", fig.cap = "Histogram of Percentile Ranks"}
hist(scores$percentileRank, xlab = "Percentile Ranks", main = "Histogram of Percentile Ranks")
```

#### Deviation (Standardized) Scores

Deviation or standardized scores are the transformation of raw scores to a normal distribution using some norm. The norm could be a comparison group, or it could be the sample itself. With deviation scores, you have similar challenges as percentile ranks including which reference group to use, but there are additional challenges. Deviation scores are more informative when the scores are normally distributed compared to when the scores are skewed. If scores are skewed, it can lead to two *z*-scores on the opposite side of the mean having different probabilities.

Many constructs we study in psychology are not normally distributed. For example, the frequency of hallucinations among people would show a positively skewed distribution with a truncation at zero, representing a floor effect—i.e., most people do not show hallucinations. For instance, consider a hypothetical distribution of hallucinations. It might follow a folded distribution:

```{r foldedDistribution, fig.align = "center", out.width = "100%", fig.cap = "Histogram of Hallucinations (Raw Score)"}
hist(rbinom(100000, 300, .01), breaks = 8, xlab = "Hallucinations (Raw Score)", main = "Histogram of Hallucinations (Raw Score)")
```

Now consider the same distribution converted to a standardized (*z*)-score:

```{r foldedDistributionZscore, fig.align = "center", out.width = "100%", fig.cap = "Histogram of Hallucinations (z-score"}
hist(scale(rbinom(100000, 300, .01)), breaks = 8, xlab = "Hallucinations (z-Score)", main = "Histogram of Hallucinations (z-Score)")
```

Thus, you can compute a deviation score, but it may not be meaningful if the data and underlying construct are not normally distributed.

##### *z*-scores

The *z*-score is the most common standardized score, and it can help putting different measures with different scales on the same playing field. *z*-scores have a mean of zero and a standard deviation of 1. To get a *z*-score that uses the sample as its own norm, subtract the mean from all scores and divide by the standard deviation. Every *z*-score represents how far that person's score is from the (normed) average, represented in standard deviation units. 68% of scores fall within one standard deviation of the mean. 95% of scores fall within 2 standard deviations of the mean. 99.7% of scores fall within three standard deviations of the mean.

*z*-scores are calculated using the following formula:

$$
z = \frac{x - \mu}{\sigma}
(\#eq:zScore)
$$

where $x$ is the observed score, $\mu$ is the mean observed score, and $\sigma$ is the standard deviation of observed scores.

```{r}
scores$zScore <- scale(scores$rawData)

all.equal(as.vector(scores$zScore),
          (scores$rawData - mean(scores$rawData, na.rm = TRUE))/sd(scores$rawData, na.rm = TRUE))
```

```{r zScores, fig.align = "center", out.width = "100%", fig.cap = "Histogram of z-Scores"}
hist(scores$zScore, xlab = "z-Scores", main = "Histogram of z-Scores")
```

##### *T*-scores

*T*-scores have a mean of 50 and a standard deviation of 10. *T*-scores are frequently used with personality and symptom measures, where clinical cutoffs are often set at 70 (i.e., two standard deviations above the mean). For the Minnesota Multiphasic Personality Inventory (MMPI), you would examine peaks (elevations $\ge$ 70) and absences ($\le$ 30).

*T*-scores are calculated using the following formula:

$$
T = 50 + 10z
$$
where $z$ are *z*-scores.

```{r}
scores$tScore <- 50 + 10*scale(scores$rawData)
```

```{r tScores, fig.align = "center", out.width = "100%", fig.cap = "Histogram of T-Scores"}
hist(scores$tScore, xlab = "T-Scores", main = "Histogram of T-Scores")
```

##### Standard scores

Standard scores have a mean of 100 and a standard deviation of 15. Standard scores are frequently used for tests of intellectual ability, academic achievement, and cognitive ability. Intellectual disability is generally considered an I.Q. less than 70 (two standard deviations below the mean), whereas giftedness is at 130 (two standard deviations above the mean).

Standard scores with a mean of 100 and standard deviation of 15 are calculated using the following formula:

$$
\text{standard score} = 100 + 15z
$$

where $z$ are *z*-scores.

```{r}
scores$standardScore <- 100 + 15*scale(scores$rawData)
```

```{r standardScores, fig.align = "center", out.width = "100%", fig.cap = "Histogram of Standard Scores"}
hist(scores$standardScore, xlab = "Standard Scores", main = "Histogram of Standard Scores")
```

##### Scaled scores

Scaled scores are raw scores that have been converted to a standardized metric. The particular metric of the scaled score depends on the measure. On tests of intellectual or cognitive ability, scaled scores commonly have a mean of 10 and a standard deviation of 3.

$$
\text{scale score} = 10 + 3z
$$

where $z$ are *z*-scores.

```{r}
scores$scaledScore <- 10 + 3*scale(scores$rawData)
```

```{r scaledScores, fig.align = "center", out.width = "100%", fig.cap = "Histogram of Scaled Scores"}
hist(scores$scaledScore, xlab = "Scale Scores", main = "Histogram of Scaled Scores")
```

##### Stanine scores

Stanine scores (short for STANdard Nine), have a mean of 5 and a standard deviation of 2. The scores range from 1–9. Stanine scores are calculated using the bracketed proportions in Table \@ref(tab:stanineCalculation). The lowest 4% receive a stanine score of 1, the next 7% receive a stanine score of 2, etc.

```{r, include = FALSE}
stanineConverstionTable <- data.frame(stanine = 1:9)
stanineConverstionTable$bracketedPercent <- c(4,7,12,17,20,17,12,7,4)
stanineConverstionTable$bracketedPercentTable <- paste(stanineConverstionTable$bracketedPercent, "%", sep = "")
stanineConverstionTable$bracketedPercent <- NULL
stanineConverstionTable$cumulativePercent <- c(4,11,23,40,60,77,89,96,100)
stanineConverstionTable$cumulativePercentTable <- paste(stanineConverstionTable$cumulativePercent, "%", sep = "")
stanineConverstionTable$cumulativePercent <- NULL
stanineConverstionTable$zScore <- c("below -1.75","-1.75 to -1.25","-1.25 to -0.75","-0.75 to -0.25","-0.25 to +0.25","+0.25 to +0.75","+0.75 to +1.25","+1.25 to +1.75","above +1.75")
stanineConverstionTable$standardScore <- c("below 74","74 to 81","81 to 89","89 to 96","96 to 104","104 to 111","111 to 119","119 to 126","above 126")

names(stanineConverstionTable) <- c("Stanine","Bracketed Percent","Cumulative Percent","z-Score","Standard Score")
```

```{r stanineCalculation, echo = FALSE}
kable(stanineConverstionTable,
      caption = "Table for Calculating Stanine Scores",
      booktabs = TRUE)
```

```{r}
scores$stanineScore <- NA
scores$stanineScore[which(scores$percentileRank <= 4)] <- 1
scores$stanineScore[which(scores$percentileRank > 4 & scores$percentileRank <= 11)] <- 2
scores$stanineScore[which(scores$percentileRank > 11 & scores$percentileRank <= 23)] <- 3
scores$stanineScore[which(scores$percentileRank > 23 & scores$percentileRank <= 40)] <- 4
scores$stanineScore[which(scores$percentileRank > 40 & scores$percentileRank <= 60)] <- 5
scores$stanineScore[which(scores$percentileRank > 60 & scores$percentileRank <= 77)] <- 6
scores$stanineScore[which(scores$percentileRank > 77 & scores$percentileRank <= 89)] <- 7
scores$stanineScore[which(scores$percentileRank > 89 & scores$percentileRank <= 96)] <- 8
scores$stanineScore[which(scores$percentileRank > 96)] <- 9
```

```{r stanineScores, fig.align = "center", out.width = "100%", fig.cap = "Histogram of Scaled Scores"}
hist(scores$stanineScore, xlab = "Stanine Scores", main = "Histogram of Stanine Scores", breaks = seq(from = 0.5, to = 9.5, by = 1), xlim = c(0,10), xaxp = c(1,9,8))
```

## Conclusion

## Suggested Readings

## Exercises
